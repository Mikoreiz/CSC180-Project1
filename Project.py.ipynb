{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "from collections.abc import Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "\n",
    "import tensorflow.keras \n",
    "\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HELPER FUNCTIONS ###\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  tsv output file for cleaned up business json dataset\n",
    "outfile = open(\"businesses.tsv\", 'w')\n",
    "businessfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL) \n",
    "businessfile.writerow(['business_id','name', 'stars', 'category'])\n",
    "\n",
    "# Opens json dataset from path. \n",
    "with open('../yelp_dataset/yelp_academic_dataset_business.json', encoding=\"utf-8\") as f: \n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # Only getting businesses with review count over 20\n",
    "        if row['review_count'] > 20:\n",
    "            # some special char must be encoded in 'utf-8' \n",
    "            businessfile.writerow([row['business_id'], row['name'], row['stars'], row['categories']])\n",
    "\n",
    "# Close tsv file\n",
    "outfile.close()\n",
    "\n",
    "# Create pandas dataframe tsv output file\n",
    "df = pd.read_csv('businesses.tsv', delimiter =\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                business_id  stars  \\\n",
      "0    oiAlXZPIFm2nBCt0DHLu_Q    5.0   \n",
      "1    oiAlXZPIFm2nBCt0DHLu_Q    1.0   \n",
      "2    oiAlXZPIFm2nBCt0DHLu_Q    5.0   \n",
      "3    oiAlXZPIFm2nBCt0DHLu_Q    1.0   \n",
      "4    oiAlXZPIFm2nBCt0DHLu_Q    5.0   \n",
      "..                      ...    ...   \n",
      "543  YZeUH6zYS0dq5QHLYZhUnQ    1.0   \n",
      "544  YZeUH6zYS0dq5QHLYZhUnQ    1.0   \n",
      "545  JjcJVqhZXhP4tvOhg3fnag    5.0   \n",
      "546  JjcJVqhZXhP4tvOhg3fnag    1.0   \n",
      "547  YZeUH6zYS0dq5QHLYZhUnQ    3.0   \n",
      "\n",
      "                                                  text  \n",
      "0    b\"I've been coming to this dry cleaner for alm...  \n",
      "1    b'They lost 2 pairs of my suitpants and told m...  \n",
      "2    b\"I have been going to this dry cleaning since...  \n",
      "3    b'I\\'ve only had my dry cleaning done here twi...  \n",
      "4    b'After reading the reviews of the cleaners cl...  \n",
      "..                                                 ...  \n",
      "543  b'I hate to give a one star, but this place ne...  \n",
      "544  b'I LOVE HOOTERS! When I came to this particul...  \n",
      "545  b'Priced out purchasing own water heater with ...  \n",
      "546  b\"Wow!!!  This guy has called me, a WOMAN and ...  \n",
      "547  b'It would be nice if they would update their ...  \n",
      "\n",
      "[548 rows x 3 columns]\n",
      "     business_id  stars                                               text\n",
      "0              3    5.0  b\"I've been coming to this dry cleaner for alm...\n",
      "1              3    1.0  b'They lost 2 pairs of my suitpants and told m...\n",
      "2              3    5.0  b\"I have been going to this dry cleaning since...\n",
      "3              3    1.0  b'I\\'ve only had my dry cleaning done here twi...\n",
      "4              3    5.0  b'After reading the reviews of the cleaners cl...\n",
      "..           ...    ...                                                ...\n",
      "543            1    1.0  b'I hate to give a one star, but this place ne...\n",
      "544            1    1.0  b'I LOVE HOOTERS! When I came to this particul...\n",
      "545            0    5.0  b'Priced out purchasing own water heater with ...\n",
      "546            0    1.0  b\"Wow!!!  This guy has called me, a WOMAN and ...\n",
      "547            1    3.0  b'It would be nice if they would update their ...\n",
      "\n",
      "[548 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Hashset for business_ids of businesses used for project\n",
    "# Will use this to search for the businesses chosen for project in the reviews json dataset\n",
    "# and add it to reviews tsv\n",
    "chosen_business = {'YZeUH6zYS0dq5QHLYZhUnQ', 'oiAlXZPIFm2nBCt0DHLu_Q', 'fNil19SUfPAPnLQrYnFrGQ', 'JjcJVqhZXhP4tvOhg3fnag'}\n",
    "\n",
    "\n",
    "#  tsv output file for cleaned up review json dataset\n",
    "outfile = open(\"review_stars.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL) \n",
    "sfile.writerow(['business_id','stars', 'text'])\n",
    "\n",
    "# Opens json dataset from path. \n",
    "with open('../yelp_dataset/yelp_academic_dataset_review.json', encoding=\"utf-8\") as f: \n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # If statement to look for our chosen businesses\n",
    "        if row['business_id'] in chosen_business: \n",
    "            # some special char must be encoded in 'utf-8' \n",
    "            sfile.writerow([row['business_id'], row['stars'], (row['text']).encode('utf-8')])\n",
    "\n",
    "# Close tsv file\n",
    "outfile.close()\n",
    "\n",
    "# Create pandas dataframe tsv output file\n",
    "df = pd.read_csv('review_stars.tsv', delimiter =\"\\t\", encoding=\"utf-8\")\n",
    "\n",
    "print(df)\n",
    "\n",
    "# One hot encoding for the 4 businesses chosen\n",
    "encode_text_index(df,\"business_id\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1.0  2.0  3.0  4.0  5.0\n",
      "0      0    0    0    0    1\n",
      "1      1    0    0    0    0\n",
      "2      0    0    0    0    1\n",
      "3      1    0    0    0    0\n",
      "4      0    0    0    0    1\n",
      "..   ...  ...  ...  ...  ...\n",
      "543    1    0    0    0    0\n",
      "544    1    0    0    0    0\n",
      "545    0    0    0    0    1\n",
      "546    1    0    0    0    0\n",
      "547    0    0    1    0    0\n",
      "\n",
      "[548 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#WE NEED TO DO THIS IN THE CSV FILE\n",
    "#then send that into tensor flow\n",
    "#!!!!!!\n",
    "texts = df['text'].to_list()\n",
    "stars = df['stars']\n",
    "\n",
    "#apply one hot endocing on stars\n",
    "stars = pd.get_dummies(stars, columns = ['stars'])\n",
    "#print(texts)        \n",
    "print(stars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['00', '10', '100', '10am', '11', '12', '13', '14', '15', '18', '1pm', '20', '24', '25', '2nd', '30', '30am', '40', '45', '4pm', '50', '700', '90', '99', '9am', 'able', 'absolutely', 'accommodate', 'accurate', 'actually', 'additional', 'advice', 'advised', 'affordable', 'afternoon', 'ago', 'agreed', 'allowed', 'alter', 'alterations', 'altered', 'amazing', 'anal', 'animal', 'animals', 'answer', 'answered', 'anymore', 'anyways', 'apologized', 'appetizer', 'appointment', 'appreciate', 'appreciated', 'area', 'areas', 'aren', 'arrived', 'ask', 'asked', 'asking', 'assistants', 'ate', 'attentive', 'attitude', 'available', 'average', 'away', 'awesome', 'awful', 'babies', 'baby', 'bad', 'bar', 'based', 'bcbg', 'beer', 'beers', 'believe', 'bentley', 'best', 'better', 'big', 'bit', 'blonde', 'blood', 'board', 'boarding', 'boneless', 'book', 'bottle', 'bottled', 'bought', 'boy', 'boyfriend', 'bradford', 'brand', 'brian', 'bring', 'bringing', 'broke', 'broken', 'brought', 'buffalo', 'burger', 'business', 'businesses', 'busted', 'busy', 'button', 'buttons', 'called', 'calling', 'calls', 'calm', 'came', 'cancellation', 'card', 'care', 'cares', 'caring', 'carry', 'case', 'cat', 'cats', 'caused', 'certainly', 'change', 'changed', 'charge', 'charged', 'charges', 'charles', 'charlie', 'cheap', 'check', 'checked', 'cheyenne', 'chicken', 'choose', 'chose', 'christmas', 'claim', 'clean', 'cleaned', 'cleaner', 'cleaners', 'cleaning', 'clearly', 'client', 'clinic', 'close', 'closed', 'clothes', 'clothing', 'code', 'coffee', 'cold', 'come', 'comes', 'comfortable', 'coming', 'communicated', 'communication', 'companies', 'company', 'compared', 'compassionate', 'competitive', 'complete', 'completed', 'completely', 'computer', 'concern', 'concerned', 'condition', 'confirmed', 'considering', 'contact', 'contacted', 'continue', 'cooked', 'correct', 'cost', 'costs', 'couldn', 'counter', 'couple', 'coupon', 'course', 'courteous', 'crazy', 'credit', 'crew', 'crying', 'current', 'customer', 'customers', 'cut', 'day', 'days', 'deal', 'dealing', 'death', 'decent', 'decided', 'decision', 'definitely', 'dental', 'depot', 'desk', 'diagnose', 'diagnosed', 'diagnosis', 'did', 'didn', 'died', 'different', 'difficult', 'dirty', 'disappoint', 'disappointed', 'discount', 'doctor', 'doctors', 'does', 'doesn', 'dog', 'dogs', 'doing', 'dollars', 'don', 'dont', 'door', 'dr', 'dress', 'drink', 'drinking', 'drinks', 'drive', 'drop', 'dropped', 'dry', 'dumb', 'ear', 'earlier', 'early', 'ears', 'ease', 'easily', 'easy', 'eat', 'eating', 'efficient', 'efficiently', 'email', 'emergency', 'employee', 'employees', 'end', 'ended', 'english', 'enjoy', 'entire', 'environment', 'especially', 'estimate', 'evening', 'exact', 'exactly', 'exam', 'excellent', 'exceptional', 'excuse', 'expect', 'expectations', 'expected', 'expensive', 'experience', 'experienced', 'explain', 'explained', 'explaining', 'expressed', 'extra', 'extremely', 'eye', 'face', 'facility', 'fact', 'failed', 'fair', 'family', 'fantastic', 'far', 'fast', 'fault', 'favorite', 'feel', 'feeling', 'fees', 'felt', 'finally', 'finding', 'fine', 'finish', 'finished', 'fit', 'fix', 'fixed', 'floor', 'flush', 'folks', 'follow', 'followed', 'following', 'food', 'forget', 'forgot', 'form', 'forms', 'forward', 'free', 'frequently', 'friday', 'friend', 'friendly', 'friends', 'fries', 'fur', 'furry', 'future', 'gallon', 'game', 'games', 'garage', 'gas', 'gave', 'gentleman', 'gets', 'getting', 'girl', 'girls', 'given', 'gives', 'giving', 'glad', 'god', 'goes', 'going', 'gone', 'good', 'got', 'gown', 'grade', 'grateful', 'great', 'green', 'greeted', 'guess', 'guy', 'guys', 'hair', 'half', 'hand', 'hands', 'happen', 'happened', 'happy', 'hard', 'hasn', 'hassle', 'haven', 'having', 'health', 'heard', 'heart', 'heater', 'heaters', 'heating', 'help', 'helped', 'helpful', 'helping', 'helps', 'hemmed', 'hesitate', 'hewitt', 'hidden', 'high', 'higher', 'highly', 'holiday', 'home', 'honest', 'honestly', 'hooters', 'hope', 'horrible', 'hospital', 'hostess', 'hot', 'hour', 'hours', 'house', 'huge', 'hung', 'husband', 'idea', 'im', 'imagine', 'immediately', 'impressed', 'included', 'including', 'incredibly', 'industry', 'infection', 'info', 'information', 'informative', 'informed', 'initial', 'inside', 'install', 'installation', 'installed', 'installer', 'instead', 'instructions', 'insurance', 'internet', 'involved', 'isn', 'issue', 'issues', 'items', 'jacket', 'job', 'just', 'justin', 'kept', 'kevin', 'kids', 'kind', 'knew', 'know', 'knowing', 'knowledge', 'knowledgeable', 'known', 'knows', 'labor', 'lack', 'lady', 'large', 'las', 'late', 'later', 'leak', 'leaking', 'leave', 'leaving', 'left', 'leg', 'let', 'letting', 'level', 'licorice', 'life', 'light', 'like', 'liked', 'line', 'listed', 'listen', 'literally', 'little', 'live', 'lived', 'lives', 'll', 'local', 'location', 'log', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lopez', 'lose', 'lost', 'lot', 'lots', 'love', 'loved', 'loves', 'loving', 'lower', 'luck', 'lucky', 'lunch', 'maintain', 'maintenance', 'major', 'make', 'makes', 'making', 'man', 'management', 'manager', 'manner', 'matter', 'mauer', 'maybe', 'meal', 'medical', 'medication', 'medicine', 'meet', 'member', 'mess', 'message', 'messed', 'met', 'min', 'mind', 'minnie', 'minor', 'mins', 'minute', 'minutes', 'missing', 'mistake', 'mistakes', 'monday', 'money', 'month', 'months', 'morning', 'mouth', 'moved', 'moving', 'multiple', 'nail', 'nails', 'ncharlie', 'ndr', 'need', 'needed', 'needs', 'new', 'nhe', 'ni', 'nice', 'nif', 'night', 'nit', 'nmy', 'non', 'noon', 'notch', 'noticed', 'nour', 'nthank', 'nthe', 'nthey', 'number', 'nwe', 'nwhen', 'obvious', 'obviously', 'offer', 'offered', 'office', 'oh', 'oil', 'ok', 'old', 'online', 'open', 'opinion', 'option', 'options', 'order', 'ordered', 'orders', 'original', 'outside', 'outstanding', 'overall', 'owner', 'owners', 'paid', 'pain', 'pair', 'pan', 'pant', 'pants', 'particular', 'parts', 'party', 'passed', 'past', 'patient', 'patients', 'patio', 'pay', 'paying', 'people', 'perfect', 'permit', 'person', 'personable', 'personal', 'pet', 'pets', 'phone', 'pick', 'picked', 'pictures', 'piece', 'pilot', 'place', 'placed', 'places', 'pleasant', 'pleased', 'plumber', 'plumbers', 'plumbing', 'plus', 'pm', 'point', 'pointed', 'policy', 'polite', 'poor', 'positive', 'possible', 'posted', 'practice', 'pretty', 'previous', 'price', 'priced', 'prices', 'pricey', 'pricing', 'prior', 'pro', 'probably', 'problem', 'problems', 'procedure', 'procedures', 'process', 'professional', 'professionalism', 'professionally', 'professionals', 'promised', 'prompt', 'promptly', 'pros', 'provide', 'provided', 'pulled', 'pup', 'puppy', 'push', 'putting', 'quality', 'question', 'questions', 'quick', 'quickly', 'quite', 'quote', 'quoted', 'quotes', 'ran', 'range', 'rare', 'rating', 'ratings', 'read', 'reading', 'ready', 'real', 'realized', 'really', 'reason', 'reasonable', 'receipts', 'receive', 'received', 'recently', 'reception', 'receptionist', 'recommend', 'recommendation', 'recommended', 'recommending', 'referred', 'regarding', 'regular', 'reliable', 'remember', 'removed', 'repair', 'replace', 'replaced', 'replacement', 'replacing', 'replied', 'reply', 'requested', 'rescue', 'reset', 'responded', 'response', 'responsibility', 'rest', 'restaurant', 'results', 'return', 'returned', 'returning', 'review', 'reviews', 'ridiculous', 'right', 'rock', 'room', 'round', 'rude', 'ruined', 'run', 'running', 'sad', 'sadly', 'said', 'salad', 'sample', 'sat', 'satisfied', 'saturday', 'sauce', 'save', 'saved', 'saw', 'say', 'saying', 'says', 'schedule', 'scheduled', 'search', 'seat', 'seated', 'seating', 'second', 'seeing', 'seen', 'send', 'sent', 'separate', 'seriously', 'server', 'servers', 'service', 'services', 'set', 'shane', 'shaver', 'shirt', 'shirts', 'shop', 'short', 'shots', 'shouldn', 'showed', 'shower', 'sick', 'sign', 'simple', 'simply', 'single', 'sit', 'sitting', 'situation', 'size', 'skills', 'skirt', 'skylar', 'small', 'smell', 'smile', 'son', 'soon', 'sorry', 'sounds', 'speak', 'special', 'specialty', 'spend', 'spending', 'spent', 'spoke', 'spot', 'spurling', 'staff', 'stain', 'stains', 'stand', 'standing', 'star', 'stars', 'start', 'started', 'stated', 'stay', 'step', 'stick', 'stop', 'stopped', 'store', 'story', 'straight', 'street', 'strongly', 'stuff', 'suggested', 'suit', 'suits', 'sunday', 'super', 'sure', 'surgery', 'surprise', 'surprised', 'sweet', 'table', 'tables', 'taken', 'takes', 'taking', 'talk', 'talked', 'talking', 'tank', 'team', 'tech', 'technician', 'technicians', 'techs', 'teeth', 'tell', 'telling', 'terrible', 'terrific', 'test', 'tests', 'text', 'thank', 'thanks', 'thing', 'things', 'think', 'thorough', 'thoroughly', 'thought', 'thursday', 'time', 'timely', 'times', 'tip', 'tips', 'toby', 'today', 'told', 'ton', 'took', 'total', 'totally', 'touch', 'town', 'training', 'treat', 'treated', 'treatment', 'treats', 'tried', 'trim', 'trip', 'truck', 'true', 'truly', 'trust', 'try', 'trying', 'tube', 'turn', 'turnaround', 'turned', 'twice', 'type', 'ultimately', 'unable', 'understand', 'understanding', 'unfortunately', 'uniform', 'unit', 'unless', 'unnecessary', 'urine', 'use', 'used', 'using', 'usually', 'vaccinations', 'vaccine', 'vaccines', 'value', 'valve', 've', 'vegas', 'vet', 'veterinarian', 'veterinary', 'vets', 'visit', 'visits', 'wait', 'waited', 'waiting', 'waitress', 'waitresses', 'walk', 'walked', 'walking', 'want', 'wanted', 'wants', 'warranty', 'wash', 'wasn', 'waste', 'watch', 'water', 'way', 'website', 'wedding', 'wednesday', 'week', 'weekend', 'weeks', 'weight', 'went', 'weren', 'west', 'white', 'whp', 'wife', 'willing', 'window', 'wing', 'wings', 'wish', 'woke', 'women', 'won', 'wonderful', 'word', 'work', 'worked', 'workers', 'working', 'works', 'world', 'worst', 'worth', 'wouldn', 'wow', 'wrap', 'write', 'writing', 'wrong', 'wtf', 'year', 'years', 'yelp', 'yelpers', 'yes', 'yesterday', 'younanian', 'zipper']\n",
      "(548, 1000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#WE NEED TO DO THIS IN THE CSV FILE\n",
    "#then send that into tensor flow\n",
    "#!!!!!!\n",
    "\n",
    "vectorizer = sk_text.TfidfVectorizer(\n",
    "                             stop_words='english',\n",
    "                             max_features = 1000,\n",
    "                             min_df=1)\n",
    "matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "print(type(matrix))          # Compressed Sparse Row matrix\n",
    "print(matrix.toarray())        #  convert it to numpy array\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(matrix.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'b\"I\\'ve been coming to this dry cleaner for almost 7 years. They are the best in town. I\\'ve tried others... thought that I could find better... I can\\'t! Great service and quality work! I also manage a luxury clothing store and I bring my stores garments there as well! I bring in simple alterations and all my dry cleaning/laundry needs!\\\\n\\\\nI am a customer for life!\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7169e99489a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"stars\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-123fdfb941da>\u001b[0m in \u001b[0;36mto_xy\u001b[0;34m(df, target)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'b\"I\\'ve been coming to this dry cleaner for almost 7 years. They are the best in town. I\\'ve tried others... thought that I could find better... I can\\'t! Great service and quality work! I also manage a luxury clothing store and I bring my stores garments there as well! I bring in simple alterations and all my dry cleaning/laundry needs!\\\\n\\\\nI am a customer for life!\"'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x,y = to_xy(df,\"stars\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1     #  why input_dim=x.shape[1]?  \n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(1)) # Output\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(x,y,verbose=2,epochs=100)    # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
